{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c99289",
   "metadata": {},
   "source": [
    "# FinancialNewsRAG Orchestrator Example\n",
    "This notebook demonstrates the functionality of the `FinancialNewsRAG` orchestrator class, which integrates various components of the financial news RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55066cd2",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "First, we need to initialize the `FinancialNewsRAG` orchestrator. This requires API keys for EODHD and Gemini, which are typically loaded from environment variables. You can also specify paths for the SQLite database and ChromaDB persistence directory.\n",
    "Make sure you have a `.env` file in your project root with `EODHD_API_KEY` and `GEMINI_API_KEY` set, or pass them directly to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from financial_news_rag.orchestrator import FinancialNewsRAG\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the orchestrator\n",
    "# Ensure EODHD_API_KEY and GEMINI_API_KEY are set in your environment or passed directly\n",
    "eodhd_api_key = os.getenv(\"EODHD_API_KEY\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not eodhd_api_key or not gemini_api_key:\n",
    "    print(\"Error: EODHD_API_KEY and GEMINI_API_KEY must be set in environment variables or passed directly.\")\n",
    "    print(\"Please create a .env file in the project root or set them in your environment.\")\n",
    "    # You might want to raise an exception here or handle it as per your application's needs\n",
    "else:\n",
    "    try:\n",
    "        # Using a unique DB path for this example to avoid conflicts with other uses\n",
    "        example_db_path = \"financial_news_rag_example.db\"\n",
    "        example_chroma_persist_dir = \"chroma_db_example\"\n",
    "        \n",
    "        orchestrator = FinancialNewsRAG(\n",
    "            eodhd_api_key=eodhd_api_key,\n",
    "            gemini_api_key=gemini_api_key,\n",
    "            db_path=example_db_path,\n",
    "            chroma_persist_dir=example_chroma_persist_dir\n",
    "        )\n",
    "        print(\"FinancialNewsRAG orchestrator initialized successfully.\")\n",
    "        print(f\"SQLite DB will be created/used at: {os.path.abspath(example_db_path)}\")\n",
    "        print(f\"ChromaDB will persist data in: {os.path.abspath(example_chroma_persist_dir)}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9718f47",
   "metadata": {},
   "source": [
    "## 2. Fetching and Storing Articles\n",
    "The `fetch_and_store_articles` method fetches news articles from the EODHD API and stores them in the SQLite database. You can fetch articles by `tag` (e.g., 'TECHNOLOGY', 'M&A') or by `symbol` (e.g., 'AAPL.US'). You can also specify `from_date`, `to_date`, and a `limit` for the number of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7722794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    # Example 1: Fetch articles by tag (e.g., 'M&A' for Mergers and Acquisitions)\n",
    "    # Using a very small limit for demonstration purposes\n",
    "    print(\"Fetching articles by tag 'MERGERS AND ACQUISITIONS' (Mergers and Acquisitions)...\")\n",
    "    fetch_results_tag = orchestrator.fetch_and_store_articles(tag=\"MERGERS AND ACQUISITIONS\", limit=20)\n",
    "    print(f\"Tag fetch results: {fetch_results_tag}\")\n",
    "    \n",
    "    # Example 2: Fetch articles by symbol (e.g., 'MSFT.US' for Microsoft)\n",
    "    print(\"Fetching articles by symbol 'MSFT.US'...\")\n",
    "    fetch_results_symbol = orchestrator.fetch_and_store_articles(symbol=\"MSFT.US\", limit=20)\n",
    "    print(f\"Symbol fetch results: {fetch_results_symbol}\")\n",
    "    \n",
    "    # Example 3: Fetch articles with a date range\n",
    "    # Note: EODHD free tier might have limitations on date ranges for news.\n",
    "    # Using a recent date range for better chances of getting results.\n",
    "    from datetime import datetime, timedelta\n",
    "    to_date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    from_date_str = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "    print(f\"Fetching articles for 'AAPL.US' from {from_date_str} to {to_date_str}...\")\n",
    "    fetch_results_date = orchestrator.fetch_and_store_articles(\n",
    "        symbol=\"AAPL.US\", \n",
    "        from_date=from_date_str, \n",
    "        to_date=to_date_str, \n",
    "        limit=20\n",
    "    )\n",
    "    print(f\"Date range fetch results: {fetch_results_date}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping fetch examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469377a6",
   "metadata": {},
   "source": [
    "## 3. Processing Articles\n",
    "The `process_articles_by_status` method retrieves articles from the database based on their processing status (e.g., 'PENDING', 'FAILED') and processes their raw content. Processing involves cleaning HTML, extracting text, and validating the content. Successfully processed articles are updated in the database with the cleaned content and a 'SUCCESS' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996332ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    # Process articles that are currently 'PENDING' (newly fetched)\n",
    "    print(\"Processing 'PENDING' articles...\")\n",
    "    processing_results_pending = orchestrator.process_articles_by_status(status='PENDING', limit=40)\n",
    "    print(f\"Pending processing results: {processing_results_pending}\")\n",
    "    \n",
    "    # Optionally, you could try to re-process 'FAILED' articles if any exist\n",
    "    # print(\"Attempting to re-process 'FAILED' articles...\")\n",
    "    # processing_results_failed = orchestrator.process_articles_by_status(status='FAILED', limit=5)\n",
    "    # print(f\"Failed processing results: {processing_results_failed}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping processing examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be877d8f",
   "metadata": {},
   "source": [
    "## 4. Embedding Articles\n",
    "The `embed_processed_articles` method takes articles that have been successfully processed and generates embeddings for their content. These embeddings are then stored in ChromaDB. This method can also handle articles whose previous embedding attempts were 'PENDING' or 'FAILED'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    # Embed articles whose content has been processed and are 'PENDING' embedding\n",
    "    print(\"Embedding 'PENDING' (embedding status) articles...\")\n",
    "    embedding_results_pending = orchestrator.embed_processed_articles(status='PENDING', limit=20)\n",
    "    print(f\"Pending embedding results: {embedding_results_pending}\")\n",
    "    \n",
    "    # Optionally, re-attempt embedding for articles that 'FAILED' previously\n",
    "    # print(\"Re-attempting to embed 'FAILED' (embedding status) articles...\")\n",
    "    # embedding_results_failed = orchestrator.embed_processed_articles(status='FAILED', limit=5)\n",
    "    # print(f\"Failed embedding results: {embedding_results_failed}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping embedding examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c5abd",
   "metadata": {},
   "source": [
    "## 5. Database Status\n",
    "You can check the status of both the article database (SQLite) and the vector database (ChromaDB) using the following methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    # Get status of the article database (SQLite)\n",
    "    print(\"Fetching article database status...\")\n",
    "    article_db_status = orchestrator.get_article_database_status()\n",
    "    print(f\"Article DB Status: {article_db_status}\")\n",
    "    \n",
    "    # Get status of the vector database (ChromaDB)\n",
    "    print(\"Fetching vector database status...\")\n",
    "    vector_db_status = orchestrator.get_vector_database_status()\n",
    "    print(f\"Vector DB Status: {vector_db_status}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping database status examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdbaf5",
   "metadata": {},
   "source": [
    "## 6. Searching Articles\n",
    "The `search_articles` method allows you to search for articles relevant to a given query. It generates an embedding for the query, searches ChromaDB for similar article chunks, retrieves the corresponding articles from SQLite, and can optionally re-rank the results using a Gemini LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals() and vector_db_status.get('total_chunks', 0) > 0:\n",
    "    # Example 1: Basic search\n",
    "    query1 = \"latest advancements in AI by Microsoft\"\n",
    "    print(f\"Searching for: '{query1}'...\")\n",
    "    search_results1 = orchestrator.search_articles(query=query1, n_results=5)\n",
    "    print(f\"Search Results 1 (basic):\")\n",
    "    for i, article in enumerate(search_results1):\n",
    "        print(f\"  {i+1}. Title: {article.get('title')}, Score: {article.get('similarity_score')}\")\n",
    "        # print(f\"     URL: {article.get('link')}\")\n",
    "        # print(f\"     Published: {article.get('published_at')}\")\n",
    "        # print(f\"     Content Snippet: {article.get('processed_content', '')[:200]}...\")\n",
    "    \n",
    "    # Example 2: Search with re-ranking\n",
    "    # Re-ranking can provide more contextually relevant results but is slower.\n",
    "    query2 = \"Apple's new product announcements\"\n",
    "    print(f\"Searching for: '{query2}' with re-ranking...\")\n",
    "    search_results2 = orchestrator.search_articles(query=query2, n_results=5, rerank=True)\n",
    "    print(f\"Search Results 2 (re-ranked):\")\n",
    "    for i, article in enumerate(search_results2):\n",
    "        print(f\"  {i+1}. Title: {article.get('title')}, Score: {article.get('relevance_score', article.get('similarity_score'))}\") # ReRanker adds 'relevance_score'\n",
    "        # print(f\"     URL: {article.get('link')}\")\n",
    "        # print(f\"     Published: {article.get('published_at')}\")\n",
    "    \n",
    "    # Example 3: Search with date filtering\n",
    "    # Assuming some articles were published in the last few days\n",
    "    from_date_search = (datetime.now() - timedelta(days=3)).isoformat() + \"Z\" # ISO format\n",
    "    to_date_search = datetime.now().isoformat() + \"Z\"\n",
    "    query3 = \"market trends\"\n",
    "    print(f\"Searching for: '{query3}' between {from_date_search} and {to_date_search}...\")\n",
    "    search_results3 = orchestrator.search_articles(\n",
    "        query=query3, \n",
    "        n_results=5, \n",
    "        from_date_str=from_date_search, \n",
    "        to_date_str=to_date_search\n",
    "    )\n",
    "    print(f\"Search Results 3 (date filtered):\")\n",
    "    for i, article in enumerate(search_results3):\n",
    "        print(f\"  {i+1}. Title: {article.get('title')}, Published: {article.get('published_at')}, Score: {article.get('similarity_score')}\")\n",
    "elif 'orchestrator' in locals():\n",
    "    print(\"Vector database is empty. Skipping search examples. Please run fetch, process, and embed steps first.\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping search examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e3970",
   "metadata": {},
   "source": [
    "## 7. Deleting Old Articles\n",
    "The `delete_articles_older_than` method removes articles from both SQLite and ChromaDB that are older than a specified number of days. This is useful for managing data retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe09292",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    # Example: Delete articles older than 365 days\n",
    "    # For this example, it's unlikely to delete anything unless you've run this over a long period.\n",
    "    # We can try with a very small number of days to see if it targets the articles we just added,\n",
    "    # but be careful as this will actually delete them.\n",
    "    print(\"Attempting to delete articles older than 1 day (for demonstration)...\")\n",
    "    # This will likely target the articles fetched if they were published more than 1 day ago.\n",
    "    # If you want to keep them, use a larger number like 365.\n",
    "    delete_results = orchestrator.delete_articles_older_than(days=1) \n",
    "    print(f\"Deletion results: {delete_results}\")\n",
    "    \n",
    "    # Check status again after deletion\n",
    "    print(\"Fetching article database status after potential deletion...\")\n",
    "    article_db_status_after_delete = orchestrator.get_article_database_status()\n",
    "    print(f\"Article DB Status: {article_db_status_after_delete}\")\n",
    "    \n",
    "    print(\"Fetching vector database status after potential deletion...\")\n",
    "    vector_db_status_after_delete = orchestrator.get_vector_database_status()\n",
    "    print(f\"Vector DB Status: {vector_db_status_after_delete}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping deletion examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a7b9b",
   "metadata": {},
   "source": [
    "## 8. Closing Connections\n",
    "Finally, the `close` method should be called to properly close database connections and release any other resources held by the orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orchestrator' in locals():\n",
    "    print(\"Closing orchestrator connections...\")\n",
    "    orchestrator.close()\n",
    "    print(\"Orchestrator connections closed.\")\n",
    "    \n",
    "    # Clean up the example database and chroma directory created by this notebook\n",
    "    # You might want to comment this out if you want to inspect the files afterwards\n",
    "    if os.path.exists(example_db_path):\n",
    "        os.remove(example_db_path)\n",
    "        print(f\"Removed example SQLite DB: {example_db_path}\")\n",
    "    if os.path.exists(example_chroma_persist_dir):\n",
    "        import shutil\n",
    "        shutil.rmtree(example_chroma_persist_dir)\n",
    "        print(f\"Removed example ChromaDB directory: {example_chroma_persist_dir}\")\n",
    "else:\n",
    "    print(\"Orchestrator not initialized. Skipping close example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07ca81",
   "metadata": {},
   "source": [
    "This concludes the demonstration of the `FinancialNewsRAG` orchestrator. You can adapt these examples to build more complex workflows for your financial news analysis tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
